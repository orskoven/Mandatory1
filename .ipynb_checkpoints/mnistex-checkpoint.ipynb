{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "036cf99d-e5c3-4e47-818c-15ebc9dc9ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST dataset...\n",
      "Dataset shape: (70000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into training, validation, and test sets...\n",
      "Training set shape: (50000, 784)\n",
      "Validation set shape: (10000, 784)\n",
      "Test set shape: (10000, 784)\n",
      "Normalizing data...\n",
      "Encoding labels...\n",
      "Use /var/folders/fd/0cmv4xlj3g39_rj20s0m475h0000gn/T/tmppk2yf93j as temporary training directory\n",
      "Use /var/folders/fd/0cmv4xlj3g39_rj20s0m475h0000gn/T/tmpfvuizbno as temporary training directory\n",
      "Compiling Neural Network models...\n",
      "** Decision Tree (TF-DF) **\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`fit` cannot consume Pandas' dataframes directly. Instead, use the `pd_dataframe_to_tf_dataset` utility function. For example: `model.fit(tfdf.keras.pd_dataframe_to_tf_dataset(train_dataframe, label=\"label_column\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 259\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# Train and evaluate each classifier\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m clf, clf_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(classifiers, classifier_names):\n\u001b[0;32m--> 259\u001b[0m     \u001b[43mtrain_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclf_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# 6. Hyperparameter Tuning for MLPClassifier\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m**Hyperparameter Tuning for MLPClassifier (sklearn)**\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 164\u001b[0m, in \u001b[0;36mtrain_evaluate_model\u001b[0;34m(clf, clf_name)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(clf, tfdf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mRandomForestModel):\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# Train the TF-DF model\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 164\u001b[0m     \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    166\u001b[0m     train_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/miniforge3/envs/tf-metal/lib/python3.9/site-packages/tensorflow_decision_forests/keras/core.py:1281\u001b[0m, in \u001b[0;36mCoreModel.fit\u001b[0;34m(self, x, y, callbacks, verbose, validation_steps, validation_data, sample_weight, steps_per_epoch, class_weight, **kwargs)\u001b[0m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;66;03m# Check for a Pandas Dataframe without injecting a dependency.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(x)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpandas.core.frame.DataFrame\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1281\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1282\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`fit` cannot consume Pandas\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m dataframes directly. Instead, use the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1283\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pd_dataframe_to_tf_dataset` utility function. For example: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1284\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`model.fit(tfdf.keras.pd_dataframe_to_tf_dataset(train_dataframe, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1285\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel_column\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m))\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1286\u001b[0m   )\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;66;03m# If the dataset was created with \"pd_dataframe_to_tf_dataset\", ensure that\u001b[39;00m\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;66;03m# the task is correctly set.\u001b[39;00m\n\u001b[1;32m   1290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_tfdf_task\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mValueError\u001b[0m: `fit` cannot consume Pandas' dataframes directly. Instead, use the `pd_dataframe_to_tf_dataset` utility function. For example: `model.fit(tfdf.keras.pd_dataframe_to_tf_dataset(train_dataframe, label=\"label_column\"))"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_decision_forests as tfdf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Suppress TensorFlow warnings\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Loading and Preprocessing Data\n",
    "# -------------------------------\n",
    "\n",
    "print(\"Loading MNIST dataset...\")\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False, data_home='~/datasets/mnist')\n",
    "\n",
    "# Check dataset shape: 70,000 samples, 784 features\n",
    "print(f\"Dataset shape: {mnist.data.shape}\")\n",
    "\n",
    "# Split data and labels into X and Y\n",
    "X = mnist.data\n",
    "Y = mnist.target.astype(int)  # Convert labels to integers\n",
    "\n",
    "# Visualize a sample image\n",
    "idx = 1030\n",
    "plt.imshow(X[idx].reshape(28,28), cmap='gray_r')\n",
    "plt.title(f\"Sample Image - Label: {Y[idx]}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Split into Training, Validation, and Test Sets\n",
    "print(\"Splitting data into training, validation, and test sets...\")\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(\n",
    "    X, Y, train_size=50000, random_state=42, stratify=Y\n",
    ")\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(\n",
    "    X_temp, Y_temp, train_size=10000, random_state=42, stratify=Y_temp\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Validation set shape: {X_val.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Preparing Data for TensorFlow Models\n",
    "# -------------------------------\n",
    "\n",
    "# Normalize the feature data\n",
    "print(\"Normalizing data...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Encode Labels for Neural Networks\n",
    "print(\"Encoding labels...\")\n",
    "lb = LabelBinarizer()\n",
    "Y_train_encoded = lb.fit_transform(Y_train)\n",
    "Y_val_encoded = lb.transform(Y_val)\n",
    "Y_test_encoded = lb.transform(Y_test)\n",
    "\n",
    "# Create DataFrames for TensorFlow Decision Forests\n",
    "feature_columns = [f\"pixel_{i}\" for i in range(X_train.shape[1])]\n",
    "train_df = pd.DataFrame(X_train, columns=feature_columns)\n",
    "train_df['label'] = Y_train\n",
    "\n",
    "test_df = pd.DataFrame(X_test, columns=feature_columns)\n",
    "test_df['label'] = Y_test\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Defining Classifiers\n",
    "# -------------------------------\n",
    "\n",
    "# Classifier Names and Definitions\n",
    "classifier_names = [\n",
    "    \"Decision Tree (TF-DF)\",\n",
    "    \"Random Forest (TF-DF)\",\n",
    "    \"Neural Net (75, 75)\",\n",
    "    \"Neural Net (784, 784, 784)\",\n",
    "    \"Naive Bayes (sklearn)\"\n",
    "]\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = [\n",
    "    # Decision Tree using TensorFlow Decision Forests\n",
    "    tfdf.keras.RandomForestModel(\n",
    "        task=tfdf.keras.Task.CLASSIFICATION,\n",
    "        num_trees=1,  # Single tree for Decision Tree\n",
    "        random_seed=42,\n",
    "    ),\n",
    "    \n",
    "    # Random Forest using TensorFlow Decision Forests\n",
    "    tfdf.keras.RandomForestModel(\n",
    "        task=tfdf.keras.Task.CLASSIFICATION,\n",
    "        num_trees=100,\n",
    "        random_seed=42,\n",
    "    ),\n",
    "    \n",
    "    # Neural Network with hidden layers (75, 75) using Keras\n",
    "    models.Sequential([\n",
    "        layers.Input(shape=(X_train_scaled.shape[1],)),\n",
    "        layers.Dense(75, activation='relu'),\n",
    "        layers.Dense(75, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')  # 10 classes for MNIST\n",
    "    ]),\n",
    "    \n",
    "    # Neural Network with hidden layers (784, 784, 784) using Keras\n",
    "    models.Sequential([\n",
    "        layers.Input(shape=(X_train_scaled.shape[1],)),\n",
    "        layers.Dense(784, activation='relu'),\n",
    "        layers.Dense(784, activation='relu'),\n",
    "        layers.Dense(784, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')  # 10 classes for MNIST\n",
    "    ]),\n",
    "    \n",
    "    # Gaussian Naive Bayes using scikit-learn\n",
    "    GaussianNB()\n",
    "]\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Compiling Neural Network Models\n",
    "# -------------------------------\n",
    "\n",
    "# Compile Keras Neural Networks\n",
    "print(\"Compiling Neural Network models...\")\n",
    "for idx, clf in enumerate(classifiers):\n",
    "    if classifier_names[idx].startswith(\"Neural Net\"):\n",
    "        clf.compile(\n",
    "            optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Training and Evaluating Classifiers\n",
    "# -------------------------------\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "training_times = []\n",
    "prediction_time_train = []\n",
    "prediction_time_test = []\n",
    "score_trains = []\n",
    "score_tests = []\n",
    "\n",
    "# Function to train and evaluate models\n",
    "def train_evaluate_model(clf, clf_name):\n",
    "    global training_times, prediction_time_train, prediction_time_test, score_trains, score_tests\n",
    "    \n",
    "    print(f\"** {clf_name} **\")\n",
    "    \n",
    "    # Check if classifier is a TensorFlow Decision Forest or Keras model or scikit-learn model\n",
    "    if isinstance(clf, tfdf.keras.RandomForestModel):\n",
    "        # Train the TF-DF model\n",
    "        start_time = time.time()\n",
    "        tf_dataset_train = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, label=\"label\")\n",
    "        clf.fit(tf_dataset_train)\n",
    "        end_time = time.time()\n",
    "        train_time = end_time - start_time\n",
    "        print(f\"\\tTraining time:\\t\\t{train_time:.3f} seconds\")\n",
    "        \n",
    "        # Predict on training subset\n",
    "        start_pred_train = time.time()\n",
    "        tf_dataset_train_subset = tfdf.keras.pd_dataframe_to_tf_dataset(train_df.iloc[:10000], label=\"label\")\n",
    "        Y_train_pred = clf.predict(tf_dataset_train_subset)\n",
    "        Y_train_pred = np.array([pred[\"label\"] for pred in Y_train_pred])\n",
    "        end_pred_train = time.time()\n",
    "        pred_time_tr = end_pred_train - start_pred_train\n",
    "        print(f\"\\tPrediction time (train):\\t{pred_time_tr:.3f} seconds\")\n",
    "        \n",
    "        # Predict on test set\n",
    "        start_pred_test = time.time()\n",
    "        tf_dataset_test = tfdf.keras.pd_dataframe_to_tf_dataset(test_df, label=\"label\")\n",
    "        Y_test_pred = clf.predict(tf_dataset_test)\n",
    "        Y_test_pred = np.array([pred[\"label\"] for pred in Y_test_pred])\n",
    "        end_pred_test = time.time()\n",
    "        pred_time_te = end_pred_test - start_pred_test\n",
    "        print(f\"\\tPrediction time (test):\\t{pred_time_te:.3f} seconds\")\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        acc_train = accuracy_score(Y_train[:10000], Y_train_pred)\n",
    "        acc_test = accuracy_score(Y_test, Y_test_pred)\n",
    "        print(f\"\\tScore Train: {acc_train:.3f}\\tScore Test: {acc_test:.3f}\")\n",
    "        \n",
    "    elif isinstance(clf, models.Sequential):\n",
    "        # Train the Keras model\n",
    "        start_time = time.time()\n",
    "        history = clf.fit(\n",
    "            X_train_scaled, Y_train_encoded,\n",
    "            epochs=20,\n",
    "            batch_size=128,\n",
    "            validation_data=(X_val_scaled, Y_val_encoded),\n",
    "            verbose=0  # Set to 1 to see training progress\n",
    "        )\n",
    "        end_time = time.time()\n",
    "        train_time = end_time - start_time\n",
    "        print(f\"\\tTraining time:\\t\\t{train_time:.3f} seconds\")\n",
    "        \n",
    "        # Predict on training subset\n",
    "        start_pred_train = time.time()\n",
    "        Y_train_pred_prob = clf.predict(X_train_scaled[:10000])\n",
    "        Y_train_pred = np.argmax(Y_train_pred_prob, axis=1)\n",
    "        end_pred_train = time.time()\n",
    "        pred_time_tr = end_pred_train - start_pred_train\n",
    "        print(f\"\\tPrediction time (train):\\t{pred_time_tr:.3f} seconds\")\n",
    "        \n",
    "        # Predict on test set\n",
    "        start_pred_test = time.time()\n",
    "        Y_test_pred_prob = clf.predict(X_test_scaled)\n",
    "        Y_test_pred = np.argmax(Y_test_pred_prob, axis=1)\n",
    "        end_pred_test = time.time()\n",
    "        pred_time_te = end_pred_test - start_pred_test\n",
    "        print(f\"\\tPrediction time (test):\\t{pred_time_te:.3f} seconds\")\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        acc_train = accuracy_score(Y_train[:10000], Y_train_pred)\n",
    "        acc_test = accuracy_score(Y_test, Y_test_pred)\n",
    "        print(f\"\\tScore Train: {acc_train:.3f}\\tScore Test: {acc_test:.3f}\")\n",
    "        \n",
    "    else:\n",
    "        # Assume scikit-learn model\n",
    "        start_time = time.time()\n",
    "        clf.fit(X_train, Y_train)\n",
    "        end_time = time.time()\n",
    "        train_time = end_time - start_time\n",
    "        print(f\"\\tTraining time:\\t\\t{train_time:.3f} seconds\")\n",
    "        \n",
    "        # Predict on training subset\n",
    "        start_pred_train = time.time()\n",
    "        Y_train_pred = clf.predict(X_train[:10000])\n",
    "        end_pred_train = time.time()\n",
    "        pred_time_tr = end_pred_train - start_pred_train\n",
    "        print(f\"\\tPrediction time (train):\\t{pred_time_tr:.3f} seconds\")\n",
    "        \n",
    "        # Predict on test set\n",
    "        start_pred_test = time.time()\n",
    "        Y_test_pred = clf.predict(X_test)\n",
    "        end_pred_test = time.time()\n",
    "        pred_time_te = end_pred_test - start_pred_test\n",
    "        print(f\"\\tPrediction time (test):\\t{pred_time_te:.3f} seconds\")\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        acc_train = accuracy_score(Y_train[:10000], Y_train_pred)\n",
    "        acc_test = accuracy_score(Y_test, Y_test_pred)\n",
    "        print(f\"\\tScore Train: {acc_train:.3f}\\tScore Test: {acc_test:.3f}\")\n",
    "    \n",
    "    # Store metrics\n",
    "    training_times.append(train_time)\n",
    "    prediction_time_train.append(pred_time_tr)\n",
    "    prediction_time_test.append(pred_time_te)\n",
    "    score_trains.append(acc_train)\n",
    "    score_tests.append(acc_test)\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for clf, clf_name in zip(classifiers, classifier_names):\n",
    "    train_evaluate_model(clf, clf_name)\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Hyperparameter Tuning for MLPClassifier\n",
    "# -------------------------------\n",
    "\n",
    "print(\"\\n**Hyperparameter Tuning for MLPClassifier (sklearn)**\")\n",
    "alphas = [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "for a in alphas:\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(75, 75), alpha=a, max_iter=20, random_state=42)\n",
    "    t0 = time.time()\n",
    "    mlp.fit(X_train, Y_train)\n",
    "    t1 = time.time()\n",
    "    score = mlp.score(X_test, Y_test)\n",
    "    print(f\"Alpha: {a} | Test Accuracy: {score:.3f} | Training Time: {t1 - t0:.3f} seconds\")\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Hyperparameter Tuning for TensorFlow Neural Networks\n",
    "# -------------------------------\n",
    "\n",
    "print(\"\\n**Hyperparameter Tuning for TensorFlow Neural Networks**\")\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "for lr in learning_rates:\n",
    "    print(f\"**Neural Net with Learning Rate: {lr}**\")\n",
    "    # Define the model\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(X_train_scaled.shape[1],)),\n",
    "        layers.Dense(75, activation='relu'),\n",
    "        layers.Dense(75, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=lr),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    t0 = time.time()\n",
    "    history = model.fit(\n",
    "        X_train_scaled, Y_train_encoded,\n",
    "        epochs=20,\n",
    "        batch_size=128,\n",
    "        validation_data=(X_val_scaled, Y_val_encoded),\n",
    "        verbose=0\n",
    "    )\n",
    "    t1 = time.time()\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    Y_test_pred_prob = model.predict(X_test_scaled)\n",
    "    Y_test_pred = np.argmax(Y_test_pred_prob, axis=1)\n",
    "    acc_test = accuracy_score(Y_test, Y_test_pred)\n",
    "    \n",
    "    print(f\"\\tTest Accuracy: {acc_test:.3f} | Training Time: {t1 - t0:.3f} seconds\")\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Summary of Metrics\n",
    "# -------------------------------\n",
    "\n",
    "# Create a DataFrame to summarize the metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Classifier': classifier_names,\n",
    "    'Training Time (s)': training_times,\n",
    "    'Prediction Time (Train) (s)': prediction_time_train,\n",
    "    'Prediction Time (Test) (s)': prediction_time_test,\n",
    "    'Score Train': score_trains,\n",
    "    'Score Test': score_tests\n",
    "})\n",
    "\n",
    "print(\"\\n**Summary of Classifier Performance**\")\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7385da84-4f96-46cd-9e14-9030715d4fba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Consolidate all metrics\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m all_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mnn_metrics\u001b[49m \u001b[38;5;241m+\u001b[39m alpha_metrics \u001b[38;5;241m+\u001b[39m hidden_layer_metrics \u001b[38;5;241m+\u001b[39m sklearn_metrics\n\u001b[1;32m      4\u001b[0m metrics_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(all_metrics)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Display the DataFrame\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "# Consolidate all metrics\n",
    "all_metrics = nn_metrics + alpha_metrics + hidden_layer_metrics + sklearn_metrics\n",
    "\n",
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "\n",
    "# Display the DataFrame\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aea780d-d06e-4bbb-b818-92dd764c4aff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow Metal",
   "language": "python",
   "name": "tf-metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
